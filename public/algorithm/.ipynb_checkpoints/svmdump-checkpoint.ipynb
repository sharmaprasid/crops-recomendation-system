{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f459cdf",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 110\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;66;03m# Train a Decision Tree classifier on the training set\u001b[39;00m\n\u001b[0;32m    109\u001b[0m clf \u001b[38;5;241m=\u001b[39m SVM()\n\u001b[1;32m--> 110\u001b[0m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_accuracy\u001b[39m(y_true, y_pred):\n\u001b[0;32m    113\u001b[0m         \u001b[38;5;66;03m# Count the number of correct predictions\u001b[39;00m\n\u001b[0;32m    114\u001b[0m         correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "Cell \u001b[1;32mIn[2], line 17\u001b[0m, in \u001b[0;36mSVM.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y):\n\u001b[1;32m---> 17\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39munique(y)\n\u001b[0;32m     18\u001b[0m     n_samples, n_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses), n_features))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from svm import SVM\n",
    "import pickle\n",
    "class SVM:\n",
    "    def __init__(self, learning_rate=0.001, lambda_param=0.01, n_iters=100, batch_size=32):\n",
    "        self.lr = learning_rate\n",
    "        self.lambda_param = lambda_param\n",
    "        self.n_iters = n_iters\n",
    "        self.batch_size = batch_size\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        self.classes = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.classes = np.unique(y)\n",
    "        n_samples, n_features = X.shape\n",
    "        self.weights = np.zeros((len(self.classes), n_features))\n",
    "        self.bias = np.zeros(len(self.classes))\n",
    "        for i, c in enumerate(self.classes):\n",
    "            y_binary = np.where(y == c, 1, -1)\n",
    "            w = np.zeros(n_features)\n",
    "            b = 0\n",
    "            for _ in range(self.n_iters):\n",
    "                indices = np.random.choice(\n",
    "                    n_samples, self.batch_size, replace=False)\n",
    "                X_batch = X[indices]\n",
    "                y_batch = y_binary[indices]\n",
    "                scores = np.dot(X_batch, w) - b\n",
    "                margins = y_batch * scores\n",
    "                misclassified = margins < 1\n",
    "                grad_w = self.lambda_param * w - \\\n",
    "                    np.dot(X_batch.T, y_batch * misclassified) / \\\n",
    "                    self.batch_size\n",
    "                grad_b = -np.sum(y_batch * misclassified) / self.batch_size\n",
    "                w -= self.lr * grad_w\n",
    "                b -= self.lr * grad_b\n",
    "            self.weights[i] = w\n",
    "            self.bias[i] = b\n",
    "\n",
    "    def predict(self, X):\n",
    "        output = np.dot(X, self.weights.T) - self.bias\n",
    "        return self.classes[np.argmax(output, axis=1)]\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('Crop_recommendation.csv')\n",
    "# Outlier removal using the IQR rule\n",
    "df=data\n",
    "#Humidity\n",
    "\n",
    "Q1 = df['humidity'].quantile(0.25)\n",
    "Q3 = df['humidity'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "df = df[(df['humidity'] >= Q1 - 1.5*IQR) & (df['humidity'] <= Q3 + 1.5*IQR)]\n",
    "# Rainfall\n",
    "Q1 = df['rainfall'].quantile(0.25)\n",
    "Q3 = df['rainfall'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "df = df[(df['rainfall'] >= Q1 - 1.5*IQR) & (df['rainfall'] <= Q3 + 1.5*IQR)]\n",
    "\n",
    "# Temperature\n",
    "Q1 = df['temperature'].quantile(0.25)\n",
    "Q3 = df['temperature'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "df = df[(df['temperature'] >= Q1 - 1.5*IQR) & (df['temperature'] <= Q3 + 1.5*IQR)]\n",
    "\n",
    "# pH\n",
    "Q1 = df['ph'].quantile(0.25)\n",
    "Q3 = df['ph'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "df = df[(df['ph'] >= Q1 - 1.5*IQR) & (df['ph'] <= Q3 + 1.5*IQR)]\n",
    "\n",
    "# N\n",
    "Q1 = df['N'].quantile(0.25)\n",
    "Q3 = df['N'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "df = df[(df['N'] >= Q1 - 1.5*IQR) & (df['N'] <= Q3 + 1.5*IQR)]\n",
    "\n",
    "# P\n",
    "Q1 = df['P'].quantile(0.25)\n",
    "Q3 = df['P'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "df = df[(df['P'] >= Q1 - 1.5*IQR) & (df['P'] <= Q3 + 1.5*IQR)]\n",
    "\n",
    "# K \n",
    "Q1 = df['K'].quantile(0.25)\n",
    "Q3 = df['K'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "df = df[(df['K'] >= Q1 - 1.5*IQR) & (df['K'] <= Q3 + 1.5*IQR)]\n",
    "\n",
    "# Split the dataset into features and target\n",
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "# Train a Decision Tree classifier on the training set\n",
    "clf = SVM()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "def calculate_accuracy(y_true, y_pred):\n",
    "        # Count the number of correct predictions\n",
    "        correct = 0\n",
    "        for i in range(len(y_true)):\n",
    "            if y_true[i] == y_pred[i]:\n",
    "                correct += 1\n",
    "    # Calculate the accuracy as a percentage\n",
    "        accuracy = (correct / len(y_true)) * 100\n",
    "        return accuracy\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "svm_acc=calculate_accuracy(y_pred,y_test)\n",
    "print(svm_acc)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "600773f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('svm_model.pkl', 'wb') as f:\n",
    "    pickle.dump((clf), f)\n",
    "with open('test.pkl', 'wb') as f:\n",
    "    pickle.dump(( X_test,y_test), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9f0044",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
